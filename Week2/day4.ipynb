{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c815b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "import ollama\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cb60097",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"Sen FlightAI adında bir havayolu için yardımcı bir asistansın. \"\n",
    "system_message += \"Kısa ve nazik cevaplar ver, 1 cümleyi geçme. \"\n",
    "system_message += \"Her zaman doğru ol. Eğer cevabı bilmiyorsan, bunu söyle.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b31b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history, model=\"llama3.2\"):\n",
    "    \"\"\"\n",
    "    Ollama Llama3.2 için chat fonksiyonu (tek seferlik cevap)\n",
    "    history: [{\"role\": \"user/assistant\", \"content\": \"...\"}]\n",
    "    \"\"\"\n",
    "    # Mesajları hazırla\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    # Ollama tek seferlik cevap\n",
    "    response = ollama.chat(model=model, messages=messages)\n",
    "    \n",
    "    return response[\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d0d3b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7877\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7877/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface( fn=chat, title=\"Ollama Chat with Llama3.2\", description=\"Chat with Llama3.2 model using Ollama API\", type=\"messages\" ).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae977136",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
    "\n",
    "def get_ticket_price(destination_city):\n",
    "    print(f\"Tool get_ticket_price called for {destination_city}\")\n",
    "    city = destination_city.lower()\n",
    "    return ticket_prices.get(city, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a939abbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool get_ticket_price called for London\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'$799'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ticket_price(\"London\")  # Example call to the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7c9ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d22cd3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\"type\": \"function\", \"function\": price_function}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "056eb4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message,history,model=\"llama3.2\"):\n",
    "    \"\"\"\n",
    "    Ollama Llama3.2 için chat fonksiyonu (tool destekli)\n",
    "    history: [{\"role\": \"user/assistant\", \"content\": \"...\"}]\n",
    "    \"\"\"\n",
    "    # Mesajları hazırla\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    # Ollama tool destekli chat\n",
    "    final_response = ollama.chat(model=model, messages=messages)\n",
    "\n",
    "    if getattr(final_response,\"finis_reason\",None)==\"tool_calls\":\n",
    "        message_from_model=final_response[\"messages\"]\n",
    "        tool_response,city = handle_tool_calls(message_from_model)\n",
    "        messages.append(message_from_model)\n",
    "        messages.append(tool_response)\n",
    "        final_response = ollama.chat(model=model, messages=messages)\n",
    "    return final_response[\"message\"][\"content\"]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79bb64ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_calls(message):\n",
    "    \"\"\"\n",
    "    Tool çağrısını işle ve bilet fiyatını döndür.\n",
    "    message: model cevabı (dict)\n",
    "    \"\"\"\n",
    "    # message içinden tool çağrısını al (OpenAI mantığı)\n",
    "    tool_call = message.get(\"tool_calls\", [])[0]  # boşsa hata vermemesi için get\n",
    "    arguments = json.loads(tool_call[\"function\"][\"arguments\"])\n",
    "    city = arguments.get(\"destination_city\")\n",
    "    \n",
    "    # Örnek: fiyatı hesapla\n",
    "    price = get_ticket_price(city)\n",
    "    \n",
    "    # Tool cevabı hazırla\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\"destination_city\": city, \"price\": price}),\n",
    "        \"tool_call_id\": tool_call[\"id\"]\n",
    "    }\n",
    "    \n",
    "    return response, city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba415160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7881\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7881/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, title=\"Ollama Chat with Llama3.2\", description=\"Chat with Llama3.2 model using Ollama API\", type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5cc808",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.10",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
